{"nbformat":4,"nbformat_minor":0,"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"colab":{"name":"_ Pytorch - EfficientNet-B0(pretrained) _nam.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AosjU7TvGerL","executionInfo":{"status":"ok","timestamp":1614431382510,"user_tz":-540,"elapsed":20441,"user":{"displayName":"남유지","photoUrl":"","userId":"01339727571231233025"}},"outputId":"f52231be-7edc-48d2-d6fd-453ef6d70e4d"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tgYQDtDnwbiN"},"source":["# 1. 데이터 불러오기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_nWzXaavGfvZ","executionInfo":{"status":"ok","timestamp":1614431649432,"user_tz":-540,"elapsed":286567,"user":{"displayName":"남유지","photoUrl":"","userId":"01339727571231233025"}},"outputId":"04906eea-28a7-4958-bcce-d89daefea1b8"},"source":["from google.colab import output\r\n","# !cp 파일1 파일2 # 파일1을 파일2로 복사 붙여넣기\r\n","!cp \"/content/drive/MyDrive/공모전/BOAZ_dacon 컴퓨터비전/data/open/data_2.zip\" \"data_2.zip\"\r\n","# data_2.zip을 현재 디렉터리에 압축해제\r\n","!unzip \"data_2.zip\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  data_2.zip\n","  inflating: dirty_mnist_2nd.zip     \n","  inflating: dirty_mnist_2nd_answer.csv  \n","  inflating: mnist_data.zip          \n","  inflating: sample_submission.csv   \n","  inflating: test_dirty_mnist_2nd.zip  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cUiRl8qlHFvJ"},"source":["from google.colab import output\r\n","# 현재 디렉터리에 dirty_mnist라는 폴더 생성\r\n","!mkdir \"./dirty_mnist\"\r\n","#dirty_mnist.zip라는 zip파일을 dirty_mnist라는 폴더에 압축 풀기\r\n","!unzip \"dirty_mnist_2nd.zip\" -d \"./dirty_mnist/\"\r\n","# 현재 디렉터리에 test_dirty_mnist라는 폴더 생성\r\n","!mkdir \"./test_dirty_mnist\"\r\n","#test_dirty_mnist.zip라는 zip파일을 test_dirty_mnist라는 폴더에 압축 풀기\r\n","!unzip \"test_dirty_mnist_2nd.zip\" -d \"./test_dirty_mnist/\"\r\n","# 출력 결과 지우기\r\n","output.clear()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FHyiQ9SQFx14"},"source":["# 2. Library Load"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-14T10:56:17.365580Z","start_time":"2021-02-14T10:56:17.348577Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"ty1jkcBQFx2B","executionInfo":{"status":"ok","timestamp":1614431764261,"user_tz":-540,"elapsed":383213,"user":{"displayName":"남유지","photoUrl":"","userId":"01339727571231233025"}},"outputId":"608c4689-234f-4c12-eb1b-a27f938aec14"},"source":["!pip install efficientnet_pytorch\n","!pip install git+https://github.com/cmpark0126/pytorch-polynomial-lr-decay.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting efficientnet_pytorch\n","  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.7.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n","Building wheels for collected packages: efficientnet-pytorch\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp37-none-any.whl size=16031 sha256=9eb19fda7fb5b788ef7b53ea92c00420290070ed42b94139bf8a1b0bde5b493e\n","  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n","Successfully built efficientnet-pytorch\n","Installing collected packages: efficientnet-pytorch\n","Successfully installed efficientnet-pytorch-0.7.0\n","Collecting git+https://github.com/cmpark0126/pytorch-polynomial-lr-decay.git\n","  Cloning https://github.com/cmpark0126/pytorch-polynomial-lr-decay.git to /tmp/pip-req-build-7bexlhbs\n","  Running command git clone -q https://github.com/cmpark0126/pytorch-polynomial-lr-decay.git /tmp/pip-req-build-7bexlhbs\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-poly-lr-decay==0.0.1) (1.7.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch-poly-lr-decay==0.0.1) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->torch-poly-lr-decay==0.0.1) (1.19.5)\n","Building wheels for collected packages: torch-poly-lr-decay\n","  Building wheel for torch-poly-lr-decay (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch-poly-lr-decay: filename=torch_poly_lr_decay-0.0.1-cp37-none-any.whl size=3833 sha256=e07b78e6b4f0adf974da3e7c1db1476a96f1e0e0db8dc8ebec6f965224df083f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-wt720ztg/wheels/5a/b7/09/d748b20c9bdfc768a33c37a28b2ad7dd9ec3e79e5152cb1618\n","Successfully built torch-poly-lr-decay\n","Installing collected packages: torch-poly-lr-decay\n","Successfully installed torch-poly-lr-decay-0.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-15T07:51:44.385690Z","start_time":"2021-02-15T07:51:41.015348Z"},"id":"Qsk4Vj8kFx2D"},"source":["import torch\n","import glob\n","import os\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","import cv2\n","from tqdm import tqdm\n","import numpy as np\n","from sklearn.model_selection import KFold\n","import time\n","from efficientnet_pytorch import EfficientNet\n","import matplotlib.pyplot as plt\n","from torch_poly_lr_decay import PolynomialLRDecay\n","import random\n","\n","import torch.nn as nn\n","import torch.utils.data as D\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","import torchvision.models as models\n","\n","\n","torch.set_num_threads(1)\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5ILIAPvPFx2E"},"source":["# 3. Dataset 구성"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-15T07:53:05.539631Z","start_time":"2021-02-15T07:53:05.527349Z"},"id":"HxtF7228Fx2H"},"source":["train_transform = T.Compose([\n","        T.RandomHorizontalFlip(),\n","        T.ToTensor(),\n","        T.Normalize((0.1307,), (0.3081,)),\n","        T.RandomAffine(20)\n","        ])\n","\n","test_transform = T.Compose([\n","        T.RandomHorizontalFlip(),\n","        T.ToTensor(),\n","        T.Normalize((0.1307,), (0.3081,)),\n","        T.RandomAffine(30)\n","        ])\n","\n","\n","class Minist_Dataset(D.Dataset):\n","    \"\"\"\n","    path = {BASE_PATH,DATA_DIR1, DATA_DIR2 ,CSV_PATH}\n","    Return: pytorch custome dataset format \n","    \"\"\"\n","    def __init__(self,\n","                 dir_path,\n","                 data,label,\n","                 transforms=train_transform,\n","                 augmentations=None):\n","        \n","        self.dir_path = dir_path # directory path\n","        self.data = data # image data\n","        self.label = label #label\n","        self.transforms = transforms# Transform\n","        #self.augmentations = augmentations\n","        \n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # global image\n","        image = image.open(self.dir_path + self.data[idx])\n","        label = self.label[idx] \n","            \n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        return image, label\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HFbKz-KUFx2I"},"source":["# reproduction을 위한 seed 설정"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-15T07:53:05.555106Z","start_time":"2021-02-15T07:53:05.540632Z"},"id":"WmdcLeuyFx2I"},"source":["# https://dacon.io/competitions/official/235697/codeshare/2363?page=1&dtype=recent&ptype=pub\n","def seed_everything(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = True  # type: ignore\n","    torch.backends.cudnn.benchmark = True  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_58OkXiZFx2J"},"source":["# 4. model 구성"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-15T07:53:05.570111Z","start_time":"2021-02-15T07:53:05.556106Z"},"id":"o6NkeZRMFx2J"},"source":["# EfficientNet -b0(pretrained)\n","# MultiLabel output\n","\n","class EfficientNet_MultiLabel(nn.Module):\n","    def __init__(self, in_channels):\n","        super(EfficientNet_MultiLabel, self).__init__()\n","        self.network = EfficientNet.from_pretrained('efficientnet-b0', in_channels=in_channels)\n","        self.output_layer = nn.Linear(1000, 26)\n","\n","    def forward(self, x):\n","        x = F.relu(self.network(x))\n","        x = torch.sigmoid(self.output_layer(x))\n","        return x\n","\n","# 모델 선언\n","#model = EfficientNet_MultiLabel(in_channels=3)\n","#model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yAZN6LmqA_j5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TpDAg3M-vqrL"},"source":["namelist = os.listdir('./dirty_mnist/')\r\n","namelist = np.array(namelist)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AsR-sUIWv4Vg"},"source":["# 5.학습"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":738},"id":"tqDnMOZJxUAN","executionInfo":{"status":"error","timestamp":1614436268458,"user_tz":-540,"elapsed":971,"user":{"displayName":"남유지","photoUrl":"","userId":"01339727571231233025"}},"outputId":"ba0ab593-5ca4-41a6-d556-3ab148fd41a9"},"source":["# cross validation을 적용하기 위해 KFold 생성\r\n","from sklearn.model_selection import KFold\r\n","kfold = KFold(n_splits=2, shuffle=True, random_state=0) # 최종에서 5로 변경\r\n","\r\n","dirty_mnist_answer = pd.read_csv(\"dirty_mnist_2nd_answer.csv\")\r\n","# dirty_mnist_answer에서 train_idx와 val_idx를 생성\r\n","best_models = [] # 폴드별로 가장 validation acc가 높은 모델 저장\r\n","for fold_index, (trn_idx, val_idx) in enumerate(kfold.split(dirty_mnist_answer),1):\r\n","    \r\n","    # cuda cache 초기화\r\n","    torch.cuda.empty_cache()\r\n","    print(trn_idx)\r\n","\r\n","    #train fold, validation fold 분할\r\n","    train_list = namelist[trn_idx]\r\n","    test_list = namelist[val_idx]\r\n","    train_answer = dirty_mnist_answer.iloc[trn_idx]\r\n","    test_answer  = dirty_mnist_answer.iloc[val_idx]\r\n","\r\n","    #Dataset 정의\r\n","    train_dataset = Minist_Dataset(\"dirty_mnist/\", train_list, train_answer)\r\n","    valid_dataset = Minist_Dataset(\"dirty_mnist/\", test_list, test_answer)\r\n","\r\n","    #DataLoader 정의\r\n","    train_data_loader = DataLoader(\r\n","        train_dataset,\r\n","        batch_size = 128,\r\n","        shuffle = True,\r\n","        num_workers = 3\r\n","    )\r\n","    valid_data_loader = DataLoader(\r\n","        valid_dataset,\r\n","        batch_size = 32,\r\n","        shuffle = False,\r\n","        num_workers = 3\r\n","    )\r\n","\r\n","    # 모델 선언\r\n","    model = EfficientNet_MultiLabel(in_channels=3)\r\n","    model = nn.DataParallel(model)\r\n","    model.to(device)# gpu에 모델 할당\r\n","\r\n","    # 훈련 옵션 설정\r\n","    optimizer = torch.optim.Adam(model.parameters(),\r\n","                                lr = 0.001)\r\n","    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\r\n","                                                step_size = 5,\r\n","                                                gamma = 0.75)\r\n","    criterion = torch.nn.BCELoss()\r\n","\r\n","    # 훈련 시작\r\n","    valid_acc_max = 0\r\n","    for epoch in range(1):\r\n","        # 1개 epoch 훈련\r\n","        train_acc_list = []\r\n","        with tqdm(train_data_loader,#train_data_loader를 iterative하게 반환\r\n","                total=train_data_loader.__len__(), # train_data_loader의 크기\r\n","                unit=\"batch\") as train_bar:# 한번 반환하는 smaple의 단위는 \"batch\"\r\n","            for i, (images, labels) in train_bar:\r\n","                train_bar.set_description(f\"Train Epoch {epoch}\")\r\n","                # 갱신할 변수들에 대한 모든 변화도를 0으로 초기화\r\n","                # 참고)https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html\r\n","                optimizer.zero_grad()\r\n","\r\n","                # tensor를 gpu에 올리기\r\n","                images = images.type(torch.FloatTensor).to(device)\r\n","                labels = labels.type(torch.FloatTensor).to(device)\r\n","\r\n","                # 모델의 dropoupt, batchnormalization를 train 모드로 설정\r\n","                model.train()\r\n","                # .forward()에서 중간 노드의 gradient를 계산\r\n","                with torch.set_grad_enabled(True):\r\n","                    # 모델 예측\r\n","                    probs  = model(images)\r\n","                    # loss 계산\r\n","                    loss = criterion(probs, labels)\r\n","                    # 중간 노드의 gradient로\r\n","                    # backpropagation을 적용하여\r\n","                    # gradient 계산\r\n","                    loss.backward()\r\n","                    # weight 갱신\r\n","                    optimizer.step()\r\n","\r\n","                    # train accuracy 계산\r\n","                    probs  = probs.cpu().detach().numpy()\r\n","                    labels = labels.cpu().detach().numpy()\r\n","                    preds = probs > 0.5\r\n","                    batch_acc = (labels == preds).mean()\r\n","                    train_acc_list.append(batch_acc)\r\n","                    train_acc = np.mean(train_acc_list)\r\n","\r\n","                # 현재 progress bar에 현재 미니배치의 loss 결과 출력\r\n","                train_bar.set_postfix(train_loss= loss.item(),\r\n","                                      train_acc = train_acc)\r\n","                \r\n","\r\n","        # 1개 epoch학습 후 Validation 점수 계산\r\n","        valid_acc_list = []\r\n","        with tqdm(valid_data_loader,\r\n","                total=valid_data_loader.__len__(),\r\n","                unit=\"batch\") as valid_bar:\r\n","            for i, (images, labels) in train_bar:\r\n","                valid_bar.set_description(f\"Valid Epoch {epoch}\")\r\n","                optimizer.zero_grad()\r\n","                images = images.type(torch.FloatTensor).to(device)\r\n","                labels = labels.type(torch.FloatTensor).to(device)\r\n","\r\n","                # 모델의 dropoupt, batchnormalization를 eval모드로 설정\r\n","                model.eval()\r\n","                # .forward()에서 중간 노드의 gradient를 계산\r\n","                with torch.no_grad():\r\n","                    # validation loss만을 계산\r\n","                    probs  = model(images)\r\n","                    valid_loss = criterion(probs, labels)\r\n","\r\n","                    # train accuracy 계산\r\n","                    probs  = probs.cpu().detach().numpy()\r\n","                    labels = labels.cpu().detach().numpy()\r\n","                    preds = probs > 0.7\r\n","                    batch_acc = (labels == preds).mean()\r\n","                    valid_acc_list.append(batch_acc)\r\n","\r\n","                valid_acc = np.mean(valid_acc_list)\r\n","                valid_bar.set_postfix(valid_loss = valid_loss.item(),\r\n","                                      valid_acc = valid_acc)\r\n","            \r\n","        # Learning rate 조절\r\n","        lr_scheduler.step()\r\n","\r\n","        # 모델 저장\r\n","        if valid_acc_max < valid_acc:\r\n","            valid_acc_max = valid_acc\r\n","            best_model = model\r\n","            MODEL = \"resnet18\"\r\n","            # 모델을 저장할 구글 드라이브 경로\r\n","            path = \"/content/drive/MyDrive/공모전/BOAZ_dacon 컴퓨터비전/notebook/models/\"\r\n","            torch.save(best_model, f'{path}{fold_index}_{MODEL}_{valid_loss.item():2.4f}_epoch_{epoch}.pth')\r\n","\r\n","    # 폴드별로 가장 좋은 모델 저장\r\n","    best_models.append(best_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","\n","  0%|          | 0/196 [00:00<?, ?batch/s]\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["[    0     2     5 ... 49991 49994 49997]\n","Loaded pretrained weights for efficientnet-b0\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/196 [00:00<?, ?batch/s]\n"],"name":"stderr"},{"output_type":"error","ename":"UnboundLocalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-8eca5f201b55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# train_data_loader의 크기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 unit=\"batch\") as train_bar:# 한번 반환하는 smaple의 단위는 \"batch\"\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mtrain_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Epoch {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0;31m# 갱신할 변수들에 대한 모든 변화도를 0으로 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnboundLocalError\u001b[0m: Caught UnboundLocalError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-58-ce8c60054339>\", line 38, in __getitem__\n    image = image.open(self.dir_path + self.data[idx])\nUnboundLocalError: local variable 'image' referenced before assignment\n"]}]},{"cell_type":"markdown","metadata":{"id":"fn7DuZMXFx2J"},"source":["# 데이터 분리\n","- 해당 코드에서는 1fold만 실행합니다.\n","- 모두 실행하려면 훈련시 반복횟수를 5로 바꾸어주면 됩니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439},"id":"mHzZ7eJDdTHK","executionInfo":{"status":"error","timestamp":1614433312898,"user_tz":-540,"elapsed":640,"user":{"displayName":"남유지","photoUrl":"","userId":"01339727571231233025"}},"outputId":"a27f5f0d-2dc9-4e3e-d4fc-bd4185058d29"},"source":["# 훈련 시작\r\n","total_step = len(train_dataloader)\r\n","best_val_acc = 0\r\n","EPOCH = 20\r\n","for epoch in range(EPOCH):\r\n","    train_acc_list = []\r\n","    running_loss = 0\r\n","    \r\n","    model.train()\r\n","    for i, (images, labels) in tqdm(enumerate(train_dataloader)):\r\n","        images = images.type(torch.FloatTensor).to(device)\r\n","        labels = labels.type(torch.FloatTensor).to(device)\r\n","        \r\n","        optimizer.zero_grad()\r\n","\r\n","        probs= model(images)\r\n","        loss = criterion(probs, labels)\r\n","        loss.backward()\r\n","        optimizer.step()\r\n","        \r\n","        running_loss += loss.item()\r\n","        \r\n","        probs  = probs.cpu().detach().numpy()\r\n","        labels = labels.cpu().detach().numpy()\r\n","        preds = probs > 0.75\r\n","        batch_acc = (labels == preds).mean()\r\n","        train_acc_list.append(batch_acc)\r\n","    \r\n","    train_acc = np.mean(train_acc_list)\r\n","    print(f'Epoch [{epoch+1}/{EPOCH}], Step [{i+1}/{total_step}], Loss: {running_loss/total_step}, Acc {train_acc}')\r\n","\r\n","    model.eval()\r\n","    valid_acc_list = []\r\n","    with torch.no_grad():\r\n","        correct = 0\r\n","        total = 0\r\n","\r\n","        for images, labels in val_dataloader:\r\n","            images = images.type(torch.FloatTensor).to(device)\r\n","            labels = labels.type(torch.FloatTensor).to(device)\r\n","\r\n","            probs = model(images)\r\n","            valid_loss = criterion(probs, labels)\r\n","\r\n","            probs  = probs.cpu().detach().numpy()\r\n","            labels = labels.cpu().detach().numpy()\r\n","            preds = probs > 0.75\r\n","            batch_acc = (labels == preds).mean()\r\n","            valid_acc_list.append(batch_acc)\r\n","            \r\n","        val_acc = np.mean(valid_acc_list)\r\n","        print(f'Validation acc: {val_acc}')\r\n","\r\n","    lr_scheduler.step()\r\n","    if val_acc > best_val_acc:\r\n","        best_val_acc = val_acc\r\n","        save('best', save_dir, epoch, model, optimizer)\r\n","    save('last', save_dir, epoch, model, optimizer)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","0it [00:00, ?it/s]\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"error","ename":"UnboundLocalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-bfd93b38dff8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-3926c510a86b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'image' referenced before assignment"]}]},{"cell_type":"markdown","metadata":{"id":"09LbvE_dFx2L"},"source":["# Test"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-15T07:53:13.553046Z","start_time":"2021-02-15T07:53:05.586601Z"},"id":"BgI4aiHVFx2L","outputId":"41a89e8f-4df7-41d0-905c-c8e951027bf5"},"source":["test_namelist = os.listdir('./test_dirty_mnist/')\n","test_labels = pd.read_csv(\"sample_submission.csv\").to_numpy()[:, 1:]\n","\n","test_transforms = T.Compose([\n","    T.RandomHorizontalFlip(),\n","    T.ToTensor(),\n","    T.Normalize((0.1307,), (0.3081,)),\n","    T.RandomAffine(20)\n","])\n","\n","test_dataset = CustomDataset('./test_dirty_mnist/', test_namelist, test_labels, test_transforms)\n","test_dataloader =  torch.utils.data.DataLoader(test_dataset, shuffle=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:07<00:00, 645.88it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"m6nwxEdwFx2L"},"source":["# Test 추론\n"]},{"cell_type":"code","metadata":{"ExecuteTime":{"end_time":"2021-02-15T07:53:30.656684Z","start_time":"2021-02-15T07:53:15.778009Z"},"run_control":{"marked":true},"id":"pMFbgrRgFx2M","outputId":"cb535994-9455-47fe-b428-1651f00f71a5"},"source":["# model.load_state_dict(torch.load('save_file/best.path.tar'))\n","model.eval()\n","prediction_list = []\n","with torch.no_grad():\n","    for images, labels in tqdm(test_dataloader):\n","        images = images.type(torch.FloatTensor).to(device)\n","        labels = labels.type(torch.FloatTensor).to(device)\n","\n","        probs = model(images)\n","        \n","        probs = probs.cpu().detach().numpy()\n","        preds = probs > 0.75\n","        prediction_list.append(preds[0].astype(np.int))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loaded pretrained weights for efficientnet-b0\n"],"name":"stdout"},{"output_type":"stream","text":["  0%|                                                                                          | 0/157 [00:00<?, ?it/s]C:\\Users\\JeongMyeong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  del sys.path[0]\n","100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:13<00:00, 12.01it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"5vaLdo44Fx2M"},"source":["# 제출물 생성"]},{"cell_type":"code","metadata":{"id":"0oMlozfVmqx5"},"source":["file_name = '/content/drive/MyDrive/공모전/BOAZ_dacon 컴퓨터비전/Efficient_epoch20_prediction'\r\n","\r\n","test_labels_DF = pd.read_csv(\"sample_submission.csv\")\r\n","test_labels_DF.iloc[:, 1:] = prediction_list\r\n","test_labels_DF.to_csv(file_name +'.csv', index=False)"],"execution_count":null,"outputs":[]}]}