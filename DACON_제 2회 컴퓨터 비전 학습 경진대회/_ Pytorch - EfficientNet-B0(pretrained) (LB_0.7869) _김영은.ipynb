{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T10:56:17.365580Z",
     "start_time": "2021-02-14T10:56:17.348577Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install efficientnet_pytorch\n",
    "# !pip install git+https://github.com/cmpark0126/pytorch-polynomial-lr-decay.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:51:44.385690Z",
     "start_time": "2021-02-15T07:51:41.015348Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import glob\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_poly_lr_decay import PolynomialLRDecay\n",
    "import random\n",
    "\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dacon Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:51:45.197411Z",
     "start_time": "2021-02-15T07:51:44.934714Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('dataset/dirty_mnist_2nd_answer.csv')[:]\n",
    "imgs_dir = np.array(sorted(glob.glob('dataset/dirty_mnist_2nd/*')))[:]\n",
    "labels = np.array(labels_df.values[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:51:45.243339Z",
     "start_time": "2021-02-15T07:51:45.207023Z"
    }
   },
   "outputs": [],
   "source": [
    "test_imgs_dir = np.array(sorted(glob.glob('dataset/test_dirty_mnist_2nd/*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:53:05.524347Z",
     "start_time": "2021-02-15T07:51:46.458046Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 50000/50000 [01:13<00:00, 679.42it/s]\n"
     ]
    }
   ],
   "source": [
    "imgs=[]\n",
    "for path in tqdm(imgs_dir[:]):\n",
    "    img=cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    imgs.append(img)\n",
    "imgs=np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:53:05.539631Z",
     "start_time": "2021-02-15T07:53:05.527349Z"
    }
   },
   "outputs": [],
   "source": [
    "# 저장소에서 load\n",
    "class MnistDataset_v1(Dataset):\n",
    "    def __init__(self, imgs_dir=None, labels=None, transform=None, train=True):\n",
    "        self.imgs_dir = imgs_dir\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 데이터 총 샘플 수\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 1개 샘플 get\n",
    "        img = cv2.imread(self.imgs_dir[idx], cv2.IMREAD_COLOR)\n",
    "        img = self.transform(img)\n",
    "        if self.train==True:\n",
    "            label = self.labels[idx]\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "        \n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "# 메모리에서 load\n",
    "class MnistDataset_v2(Dataset):\n",
    "    def __init__(self, imgs=None, labels=None, transform=None, train=True):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.train=train\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 데이터 총 샘플 수\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 1개 샘플 get1\n",
    "        img = self.imgs[idx]\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        if self.train==True:\n",
    "            label = self.labels[idx]\n",
    "            return img, label\n",
    "        else:\n",
    "            return img\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reproduction을 위한 seed 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:53:05.555106Z",
     "start_time": "2021-02-15T07:53:05.540632Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://dacon.io/competitions/official/235697/codeshare/2363?page=1&dtype=recent&ptype=pub\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:53:05.570111Z",
     "start_time": "2021-02-15T07:53:05.556106Z"
    }
   },
   "outputs": [],
   "source": [
    "# EfficientNet -b0(pretrained)\n",
    "# MultiLabel output\n",
    "\n",
    "class EfficientNet_MultiLabel(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(EfficientNet_MultiLabel, self).__init__()\n",
    "        self.network = EfficientNet.from_pretrained('efficientnet-b0', in_channels=in_channels)\n",
    "        self.output_layer = nn.Linear(1000, 26)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.network(x))\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분리\n",
    "- 해당 코드에서는 1fold만 실행합니다.\n",
    "- 모두 실행하려면 훈련시 반복횟수를 5로 바꾸어주면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:53:05.585600Z",
     "start_time": "2021-02-15T07:53:05.571112Z"
    }
   },
   "outputs": [],
   "source": [
    "# 해당 코드에서는 1fold만 실행\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds=[]\n",
    "for train_idx, valid_idx in kf.split(imgs):\n",
    "    folds.append((train_idx, valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-14T13:53:22.980199Z",
     "start_time": "2021-02-14T10:57:16.236497Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JeongMyeong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\JeongMyeong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\JeongMyeong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\JeongMyeong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold : 1\tepoch : 01\ttrain_accuracy / loss : 0.57832 / 0.67041\tvalid_accuracy / loss : 0.60466 / 0.66580\ttime : 362\n",
      "fold : 1\tepoch : 02\ttrain_accuracy / loss : 0.65314 / 0.61597\tvalid_accuracy / loss : 0.66300 / 0.62072\ttime : 362\n",
      "fold : 1\tepoch : 03\ttrain_accuracy / loss : 0.70415 / 0.56392\tvalid_accuracy / loss : 0.71476 / 0.55302\ttime : 352\n",
      "fold : 1\tepoch : 04\ttrain_accuracy / loss : 0.74050 / 0.51942\tvalid_accuracy / loss : 0.74490 / 0.51546\ttime : 351\n",
      "fold : 1\tepoch : 05\ttrain_accuracy / loss : 0.76704 / 0.48314\tvalid_accuracy / loss : 0.76168 / 0.49233\ttime : 352\n",
      "fold : 1\tepoch : 06\ttrain_accuracy / loss : 0.78603 / 0.45380\tvalid_accuracy / loss : 0.78428 / 0.45881\ttime : 351\n",
      "fold : 1\tepoch : 07\ttrain_accuracy / loss : 0.80202 / 0.42815\tvalid_accuracy / loss : 0.79765 / 0.43725\ttime : 350\n",
      "fold : 1\tepoch : 08\ttrain_accuracy / loss : 0.81593 / 0.40455\tvalid_accuracy / loss : 0.80026 / 0.43284\ttime : 351\n",
      "fold : 1\tepoch : 09\ttrain_accuracy / loss : 0.82878 / 0.38237\tvalid_accuracy / loss : 0.80241 / 0.42818\ttime : 351\n",
      "fold : 1\tepoch : 10\ttrain_accuracy / loss : 0.83914 / 0.36270\tvalid_accuracy / loss : 0.81615 / 0.41145\ttime : 351\n",
      "fold : 1\tepoch : 11\ttrain_accuracy / loss : 0.85042 / 0.34277\tvalid_accuracy / loss : 0.82639 / 0.39860\ttime : 352\n",
      "fold : 1\tepoch : 12\ttrain_accuracy / loss : 0.85896 / 0.32542\tvalid_accuracy / loss : 0.82655 / 0.39560\ttime : 353\n",
      "fold : 1\tepoch : 13\ttrain_accuracy / loss : 0.86807 / 0.30827\tvalid_accuracy / loss : 0.83070 / 0.39095\ttime : 351\n",
      "fold : 1\tepoch : 14\ttrain_accuracy / loss : 0.87599 / 0.29174\tvalid_accuracy / loss : 0.83556 / 0.38696\ttime : 350\n",
      "fold : 1\tepoch : 15\ttrain_accuracy / loss : 0.88371 / 0.27629\tvalid_accuracy / loss : 0.84089 / 0.38020\ttime : 351\n",
      "fold : 1\tepoch : 16\ttrain_accuracy / loss : 0.89066 / 0.26073\tvalid_accuracy / loss : 0.84217 / 0.38226\ttime : 356\n",
      "fold : 1\tepoch : 17\ttrain_accuracy / loss : 0.89781 / 0.24571\tvalid_accuracy / loss : 0.84180 / 0.38892\ttime : 353\n",
      "fold : 1\tepoch : 18\ttrain_accuracy / loss : 0.90419 / 0.23205\tvalid_accuracy / loss : 0.84316 / 0.39090\ttime : 352\n",
      "fold : 1\tepoch : 19\ttrain_accuracy / loss : 0.91018 / 0.21883\tvalid_accuracy / loss : 0.84408 / 0.39912\ttime : 352\n",
      "fold : 1\tepoch : 20\ttrain_accuracy / loss : 0.91642 / 0.20548\tvalid_accuracy / loss : 0.84267 / 0.40250\ttime : 351\n",
      "fold : 1\tepoch : 21\ttrain_accuracy / loss : 0.92149 / 0.19303\tvalid_accuracy / loss : 0.84390 / 0.40446\ttime : 351\n",
      "fold : 1\tepoch : 22\ttrain_accuracy / loss : 0.92699 / 0.18122\tvalid_accuracy / loss : 0.84624 / 0.41995\ttime : 351\n",
      "fold : 1\tepoch : 23\ttrain_accuracy / loss : 0.93177 / 0.17012\tvalid_accuracy / loss : 0.84559 / 0.41315\ttime : 351\n",
      "fold : 1\tepoch : 24\ttrain_accuracy / loss : 0.93661 / 0.15866\tvalid_accuracy / loss : 0.84650 / 0.43195\ttime : 351\n",
      "fold : 1\tepoch : 25\ttrain_accuracy / loss : 0.94149 / 0.14790\tvalid_accuracy / loss : 0.84525 / 0.44565\ttime : 351\n",
      "fold : 1\tepoch : 26\ttrain_accuracy / loss : 0.94508 / 0.13914\tvalid_accuracy / loss : 0.84702 / 0.45223\ttime : 351\n",
      "fold : 1\tepoch : 27\ttrain_accuracy / loss : 0.94895 / 0.13039\tvalid_accuracy / loss : 0.84784 / 0.46655\ttime : 352\n",
      "fold : 1\tepoch : 28\ttrain_accuracy / loss : 0.95219 / 0.12266\tvalid_accuracy / loss : 0.84748 / 0.47613\ttime : 351\n",
      "fold : 1\tepoch : 29\ttrain_accuracy / loss : 0.95533 / 0.11458\tvalid_accuracy / loss : 0.84822 / 0.48212\ttime : 351\n",
      "fold : 1\tepoch : 30\ttrain_accuracy / loss : 0.95781 / 0.10987\tvalid_accuracy / loss : 0.84855 / 0.48876\ttime : 351\n"
     ]
    }
   ],
   "source": [
    "### seed_everything(42)\n",
    "\n",
    "# 5개의 fold 모두 실행하려면 for문을 5번 돌리면 됩니다.\n",
    "for fold in range(1):\n",
    "    model = EfficientNet_MultiLabel(in_channels=3).to(device)\n",
    "#     model = nn.DataParallel(model)\n",
    "    train_idx = folds[fold][0]\n",
    "    valid_idx = folds[fold][1]\n",
    "\n",
    "\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip()\n",
    "        ])\n",
    "    valid_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "\n",
    "    epochs=30\n",
    "    batch_size=47         # 자신의 VRAM에 맞게 조절해야 OOM을 피할 수 있습니다.\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Data Loader\n",
    "    train_dataset = MnistDataset_v2(imgs = imgs[train_idx], labels=labels[train_idx], transform=train_transform)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    valid_dataset = MnistDataset_v2(imgs = imgs[valid_idx], labels = labels[valid_idx], transform=valid_transform)\n",
    "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False)       \n",
    "    \n",
    "    \n",
    "    # optimizer\n",
    "    # polynomial optimizer를 사용합니다.\n",
    "    # \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "    decay_steps = (len(train_dataset)//batch_size)*epochs\n",
    "    scheduler_poly_lr_decay = PolynomialLRDecay(optimizer, max_decay_steps=decay_steps, end_learning_rate=1e-6, power=0.9)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    \n",
    "    \n",
    "    epoch_accuracy = []\n",
    "    valid_accuracy = []\n",
    "    valid_losses=[]\n",
    "    valid_best_accuracy=0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        batch_accuracy_list = []\n",
    "        batch_loss_list = []\n",
    "        start=time.time()\n",
    "        for n, (X, y) in enumerate((train_loader)):\n",
    "            X = torch.tensor(X, device=device, dtype=torch.float32)\n",
    "            y = torch.tensor(y, device=device, dtype=torch.float32)\n",
    "            y_hat = model(X)\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler_poly_lr_decay.step()\n",
    "\n",
    "            \n",
    "            y_hat  = y_hat.cpu().detach().numpy()\n",
    "            y_hat = y_hat>0.5\n",
    "            y = y.cpu().detach().numpy()\n",
    "\n",
    "            batch_accuracy = (y_hat == y).mean()\n",
    "            batch_accuracy_list.append(batch_accuracy)\n",
    "            batch_loss_list.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        valid_batch_accuracy=[]\n",
    "        valid_batch_loss = []\n",
    "        with torch.no_grad():\n",
    "            for n_valid, (X_valid, y_valid) in enumerate((valid_loader)):\n",
    "                X_valid = torch.tensor(X_valid, device=device)#, dtype=torch.float32)\n",
    "                y_valid = torch.tensor(y_valid, device=device, dtype=torch.float32)\n",
    "                y_valid_hat = model(X_valid)\n",
    "                \n",
    "                valid_loss = criterion(y_valid_hat, y_valid).item()\n",
    "                \n",
    "                y_valid_hat = y_valid_hat.cpu().detach().numpy()>0.5\n",
    "                \n",
    "                \n",
    "                valid_batch_loss.append(valid_loss)\n",
    "                valid_batch_accuracy.append((y_valid_hat == y_valid.cpu().detach().numpy()).mean())\n",
    "                \n",
    "            valid_losses.append(np.mean(valid_batch_loss))\n",
    "            valid_accuracy.append(np.mean(valid_batch_accuracy))\n",
    "            \n",
    "        if np.mean(valid_batch_accuracy)>valid_best_accuracy:\n",
    "            torch.save(model.state_dict(), 'model/EfficientNetB0-fold{}.pt'.format(fold))\n",
    "            valid_best_accuracy = np.mean(valid_batch_accuracy)\n",
    "        print('fold : {}\\tepoch : {:02d}\\ttrain_accuracy / loss : {:.5f} / {:.5f}\\tvalid_accuracy / loss : {:.5f} / {:.5f}\\ttime : {:.0f}'.format(fold+1, epoch+1,\n",
    "                                                                                                                                              np.mean(batch_accuracy_list),\n",
    "                                                                                                                                              np.mean(batch_loss_list),\n",
    "                                                                                                                                              np.mean(valid_batch_accuracy), \n",
    "                                                                                                                                              np.mean(valid_batch_loss),\n",
    "                                                                                                                                              time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Image 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:53:13.553046Z",
     "start_time": "2021-02-15T07:53:05.586601Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:07<00:00, 645.88it/s]\n"
     ]
    }
   ],
   "source": [
    "test_imgs=[]\n",
    "for path in tqdm(test_imgs_dir):\n",
    "    test_img=cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    test_imgs.append(test_img)\n",
    "test_imgs=np.array(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:53:13.568049Z",
     "start_time": "2021-02-15T07:53:13.554047Z"
    }
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 추론\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:53:30.656684Z",
     "start_time": "2021-02-15T07:53:15.778009Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/157 [00:00<?, ?it/s]C:\\Users\\JeongMyeong\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  del sys.path[0]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:13<00:00, 12.01it/s]\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('dataset/sample_submission.csv')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for fold in range(1):\n",
    "        model = EfficientNet_MultiLabel(in_channels=3).to(device)\n",
    "        model.load_state_dict(torch.load('model/EfficientNetB0-fold{}.pt'.format(fold)))\n",
    "        model.eval()\n",
    "\n",
    "        test_dataset = MnistDataset_v2(imgs = test_imgs, transform=test_transform, train=False)\n",
    "        test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        for n, X_test in enumerate(tqdm(test_loader)):\n",
    "            X_test = torch.tensor(X_test, device=device, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                pred_test = model(X_test).cpu().detach().numpy()\n",
    "                submission.iloc[n*32:(n+1)*32,1:] += pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:53:31.729012Z",
     "start_time": "2021-02-15T07:53:31.675328Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.iloc[:,1:] = np.where(submission.values[:,1:]>=0.5, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-15T07:53:41.514767Z",
     "start_time": "2021-02-15T07:53:41.484769Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('EfficientNetB0-fold0.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
